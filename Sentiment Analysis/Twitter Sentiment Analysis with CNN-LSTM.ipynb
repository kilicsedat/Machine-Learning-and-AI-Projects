{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv', encoding = \"ISO-8859-1\")\n",
    "#test_data=pd.read_csv('test.csv', encoding = \"ISO-8859-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessString(text):\n",
    "    #Strips quotes at end of text\n",
    "    text=text.strip('')\n",
    "    #Rmoving twitter handles @user\n",
    "    text=re.sub(\"@[\\w]*\",\" \",text) \n",
    "    # Remove URLs with the space\n",
    "    text = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' ', text)\n",
    "    # Strip space, \" and ' from text\n",
    "    text = text.strip(' \"\\'')\n",
    "    #remove digits\n",
    "    #text = re.sub(r'(\\d)', '', text)\n",
    "    #Remove repeated letters of string such as jusssssst to just \n",
    "    text=re.sub(r'(.)\\1{3,}', r'\\1', text)\n",
    "    # remove all special characters\n",
    "    text = re.sub('[^A-Za-z]', ' ', text)\n",
    "    #replace two or more dots with space\n",
    "    text = re.sub(\"\\\\.{2,}\",\" \",text);\n",
    "    # converting all text into small letters and store them as words for further processing\n",
    "    text_list = text.lower().split()\n",
    "     # stemming the words (removing prefix and postfix) using Porter stemming algorithm..\n",
    "    text_list = [ps.stem(word) for word in text_list]\n",
    "    return ' '.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Preprocessed_data']=data['SentimentText'].apply(preProcessString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "train, test = train_test_split(data, test_size=0.20)\n",
    "Count_vectorization=TfidfVectorizer(use_idf=True, max_features=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (79991, 200)\n",
      "x_test shape: (19998, 200)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 63992 samples, validate on 15999 samples\n",
      "Epoch 1/3\n",
      "63992/63992 [==============================] - 495s 8ms/step - loss: 0.5310 - acc: 0.7297 - val_loss: 0.5015 - val_acc: 0.7533\n",
      "Epoch 2/3\n",
      "63992/63992 [==============================] - 339s 5ms/step - loss: 0.4831 - acc: 0.7640 - val_loss: 0.4935 - val_acc: 0.7596\n",
      "Epoch 3/3\n",
      "63992/63992 [==============================] - 329s 5ms/step - loss: 0.4516 - acc: 0.7824 - val_loss: 0.4960 - val_acc: 0.7605\n",
      "19998/19998 [==============================] - 24s 1ms/step\n",
      "Test score: 0.5073296641013493\n",
      "Test accuracy: 0.7564256425404122\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "# Embedding\n",
    "max_features = 2000\n",
    "maxlen = 200\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 3\n",
    "filters = 250\n",
    "pool_size = 2\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "x_train = train[\"Preprocessed_data\"]\n",
    "y_train = train[\"Sentiment\"]\n",
    "x_test  = test[\"Preprocessed_data\"]\n",
    "y_test  = test[\"Sentiment\"]\n",
    "\n",
    "x_train = [one_hot(d, max_features) for d in x_train]\n",
    "y_train = np.asarray(y_train)\n",
    "x_test  = [one_hot(d, max_features) for d in x_test]\n",
    "y_test  = np.asarray(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.2, epochs=epochs)\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
