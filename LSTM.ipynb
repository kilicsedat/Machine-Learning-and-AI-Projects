{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', header = None, usecols = [1,2], nrows = None, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern= r'(\\w+|\\!+|\\.+|\\,+|\\?+)'\n",
    "def findmatches(sentences):\n",
    "    output = []\n",
    "    for sen in sentences:\n",
    "        match= re.findall(pattern, sen)\n",
    "        cleaned = []\n",
    "        for word in match:\n",
    "            if word.find('.')>-1 :\n",
    "                \n",
    "                cleaned.append('.')\n",
    "            elif word.find(',')>-1  :\n",
    "                cleaned.append(',')\n",
    "            elif word.find('?')>-1  :\n",
    "                cleaned.append('?')\n",
    "            elif word.find('!')>-1  :\n",
    "                cleaned.append('!')\n",
    "            else:\n",
    "                cleaned.append(word)\n",
    "\n",
    "        output.append(cleaned)\n",
    "    return output\n",
    "\n",
    "sentences = findmatches( df.values[1:][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetWords(sentences) :\n",
    "\n",
    "    words = []\n",
    "    for tokens in sentences:\n",
    "        for word in tokens:\n",
    "            words.append(word)\n",
    "\n",
    "    words = set(words)\n",
    "\n",
    "    words = sorted(words)\n",
    "\n",
    "    AllWords = list(words)\n",
    "\n",
    "    return AllWords\n",
    "\n",
    "Words = GetWords(sentences)"
   ]
  },
  {
   
   "source": [
    "def ElmoEmbedding(tokens_input):\n",
    "\n",
    "    Dict = {}\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    batch = 1000\n",
    "\n",
    "    LenOfEmbedding = 0\n",
    "\n",
    "    for i in range(int(len(tokens_input)/batch)+1) :\n",
    "        embeddings = elmo(tokens_input[i*batch:(i+1)*batch])\n",
    "        temp = sess.run(embeddings)\n",
    "        if((len(temp))> 0):\n",
    "            LenOfEmbedding= len(temp[0])\n",
    "        for k,word in enumerate(tokens_input[i*batch:(i+1)*batch]):\n",
    "            Dict[tokens_input[i*batch+k]]= temp[k]\n",
    "    sess.close()\n",
    "\n",
    "    return (Dict,LenOfEmbedding)\n",
    "\n",
    "def GetTokensEmbedding(embeddings, sentences):\n",
    "    return [[word for worn in sen] for sen in sentences ]\n",
    "\n",
    "(AllEmbeddings,LenOfEmbedding) = ElmoEmbedding(Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = [int(a) for a in df.values[1:][:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "import copy\n",
    "from datetime import datetime\n",
    "np.random.seed(1)\n",
    "\n",
    "def preprocessing(input):\n",
    "    newInput = []\n",
    "    maxLen = max([len(l) for l in input])\n",
    "    for sentence in input:\n",
    "        currEmbedding = copy.deepcopy(sentence)\n",
    "        curLen = len(sentence)\n",
    "        if(curLen < maxLen) :\n",
    "            newSentence = np.zeros(len(sentence[0]))\n",
    "            for i in range(curLen,maxLen) :\n",
    "                currEmbedding.append(newSentence)\n",
    "        newInput.append(currEmbedding)\n",
    "    return newInput\n",
    "\n",
    "def LSTMModel(vectorLength):\n",
    "    #embedding = Input()\n",
    "    net_input = Input(shape=(None,vectorLength))\n",
    "    X = LSTM(128, return_sequences=True)(net_input)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(1, activation=None)(X)\n",
    "    X = Activation('sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=net_input, outputs=X)\n",
    "\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 78s 8s/step - loss: 0.6639 - acc: 0.7500\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5565 - acc: 0.7800\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5579 - acc: 0.7500\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6044 - acc: 0.7500\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5488 - acc: 0.7900\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.5438 - acc: 0.7800\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5730 - acc: 0.7400\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5158 - acc: 0.8100\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5576 - acc: 0.7500\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5549 - acc: 0.7600\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6009 - acc: 0.7200\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5788 - acc: 0.7400\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5503 - acc: 0.7700\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.4730 - acc: 0.8300\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5675 - acc: 0.7600\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5945 - acc: 0.7100\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5252 - acc: 0.8100\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5686 - acc: 0.7400\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5695 - acc: 0.7500\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5806 - acc: 0.7400\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5210 - acc: 0.7900\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5560 - acc: 0.7500\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.4576 - acc: 0.8300\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5604 - acc: 0.7600\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6515 - acc: 0.6700\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5855 - acc: 0.7400\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5391 - acc: 0.7900\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5475 - acc: 0.7800\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5770 - acc: 0.7300\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5834 - acc: 0.7200\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5804 - acc: 0.7400\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 35s 4s/step - loss: 0.5774 - acc: 0.7400\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5003 - acc: 0.8200\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5219 - acc: 0.7900\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5438 - acc: 0.7700\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5582 - acc: 0.7500\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6038 - acc: 0.7100\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5939 - acc: 0.7200\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6056 - acc: 0.7100\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6177 - acc: 0.7000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5578 - acc: 0.7500\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6028 - acc: 0.7100\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5034 - acc: 0.8100\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5938 - acc: 0.7400\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6285 - acc: 0.7000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5945 - acc: 0.7400\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6672 - acc: 0.6500\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6212 - acc: 0.7100\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5519 - acc: 0.7900\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5278 - acc: 0.7800\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5539 - acc: 0.7600\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6361 - acc: 0.6900\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5887 - acc: 0.7200\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5624 - acc: 0.7500\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5644 - acc: 0.7500\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5900 - acc: 0.7300\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5589 - acc: 0.7700\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5818 - acc: 0.7300\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6385 - acc: 0.6900\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5853 - acc: 0.7300\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5947 - acc: 0.7200\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6095 - acc: 0.7100\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.5501 - acc: 0.7700\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5602 - acc: 0.7500\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5954 - acc: 0.7200\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5139 - acc: 0.8000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5706 - acc: 0.7600\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6056 - acc: 0.7100\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5153 - acc: 0.8000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5749 - acc: 0.7400\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6230 - acc: 0.7000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5669 - acc: 0.7600\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5278 - acc: 0.8000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6184 - acc: 0.7000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.4886 - acc: 0.8200\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5427 - acc: 0.7600\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6054 - acc: 0.7200\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5898 - acc: 0.7200\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5250 - acc: 0.7900\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5579 - acc: 0.7600\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5758 - acc: 0.7400\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5651 - acc: 0.7500\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.6047 - acc: 0.7100\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5631 - acc: 0.7600\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5640 - acc: 0.7400\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5227 - acc: 0.7700\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.4758 - acc: 0.8200\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5600 - acc: 0.7700\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5384 - acc: 0.7800\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5159 - acc: 0.7900\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5435 - acc: 0.7700\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5424 - acc: 0.7700\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5871 - acc: 0.7400\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5670 - acc: 0.7500\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.5644 - acc: 0.7600\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5628 - acc: 0.7600\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5933 - acc: 0.7100\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 37s 4s/step - loss: 0.5658 - acc: 0.7500\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6193 - acc: 0.7000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 38s 4s/step - loss: 0.6056 - acc: 0.7100\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-85b060a5d6aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerateInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLenOfEmbedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAllEmbeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerateOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLenOfEmbedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAllEmbeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     \u001b[1;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[1;34m(uid)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \"\"\"\n\u001b[1;32m--> 626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-85b060a5d6aa>\u001b[0m in \u001b[0;36mgenerateOutput\u001b[1;34m(sents, labs, batch_size, LenOfEmbedding, maxL, AllEmbeddings)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32myield\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m--> 501\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def generateInput(sents,labs,batch_size,LenOfEmbedding,maxL,AllEmbeddings):\n",
    "    while True:\n",
    "        combined = copy.deepcopy(list(zip(sents,labs)))\n",
    "        random.seed(datetime.now())\n",
    "        random.shuffle(combined)\n",
    "        column = np.zeros(LenOfEmbedding)\n",
    "        (sentences, labels) = list(zip(*combined))\n",
    "\n",
    "        X = []\n",
    "        for sen in sentences[:batch_size]:\n",
    "            embed = []\n",
    "            for word in sen:\n",
    "                embed.append(AllEmbeddings[word])\n",
    "            for i in range(len(embed),maxL):\n",
    "                embed.append(column)\n",
    "            X.append(embed)\n",
    "        Y = [y for y in labels[:batch_size]]\n",
    "        yield(np.asarray(X), np.asarray(Y))\n",
    "\n",
    "def generateOutput(sents,labs,batch_size,LenOfEmbedding,maxL,AllEmbeddings):\n",
    "    i = 0\n",
    "    while True:\n",
    "        combined = copy.deepcopy(list(zip(sents,labs)))\n",
    "        (sentences, labels) = list(zip(*combined))\n",
    "        column = np.zeros(LenOfEmbedding)\n",
    "        X = []\n",
    "        for sen in sentences[:batch_size]:\n",
    "            embed = []\n",
    "            for word in sen:\n",
    "                embed.append(AllEmbeddings[word])\n",
    "            for i in range(len(embed),maxL):\n",
    "                embed.append(column)\n",
    "            X.append(embed)\n",
    "        Y = [y for y in labels[:batch_size]]\n",
    "        i=i+1\n",
    "        yield(np.asarray(X), np.asarray(Y))\n",
    "\n",
    "\n",
    "partition = 100\n",
    "nrows = 200\n",
    "epoch = 100\n",
    "batch_size = 10\n",
    "\n",
    "model = LSTMModel(LenOfEmbedding)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "maxL = max([len(s) for s in sentences])\n",
    "\n",
    "model.fit_generator(generateInput(sentences[:partition],Labels[:partition],batch_size,LenOfEmbedding,maxL,AllEmbeddings),int(partition/batch_size), epochs = epoch)\n",
    "\n",
    "loss, acc, f1_score, precision, recall = model.evaluate_generator(generateOutput(sentences[partition:],Labels[partition:],len(Labels[partition:]),LenOfEmbedding,maxL,AllEmbeddings),1)\n",
    "\n",
    "print(\"Test accuracy = \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
